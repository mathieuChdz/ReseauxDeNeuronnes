{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a1a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "Aligned pairs: 8000\n",
      "Building cache (only once)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:00<00:00, 17754.72it/s]\n",
      "Epoch 1/6:   4%|▍         | 308/8000 [01:10<35:42,  3.59it/s, loss=0.13]  "
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# 1) DEVICE\n",
    "# ============================\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# ============================\n",
    "# 2) PATHS\n",
    "# ============================\n",
    "DEG_DIR = \"../data/train/degraded_images\"\n",
    "HR_DIR  = \"../data/train/images\"\n",
    "\n",
    "CACHE_DIR = \"cache_color\"\n",
    "CHECKPOINT_DIR = \"checkpoints_color\"\n",
    "GRID_DIR = \"samples_color\"\n",
    "\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(GRID_DIR, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 3) TRANSFORMS\n",
    "# ============================\n",
    "transform_rgb = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),  # [0,1]\n",
    "])\n",
    "\n",
    "# ============================\n",
    "# 4) LUMA (pseudo grayscale)\n",
    "# ============================\n",
    "def rgb_to_luma(rgb01):\n",
    "    r, g, b = rgb01[0], rgb01[1], rgb01[2]\n",
    "    y = 0.299*r + 0.587*g + 0.114*b\n",
    "    return y.unsqueeze(0)  # [1,H,W]\n",
    "\n",
    "# ============================\n",
    "# 5) DATASET + CACHE\n",
    "# ============================\n",
    "class ColorDataset(Dataset):\n",
    "    \"\"\"\n",
    "    On fait simple :\n",
    "    Input = Luma(degraded)  [1,H,W]\n",
    "    Target = HR RGB         [3,H,W]\n",
    "\n",
    "    Cache = accélère énormément (sinon on relit + resize + calcule à chaque epoch)\n",
    "    \"\"\"\n",
    "    def __init__(self, deg_dir, hr_dir, cache_dir, max_items=8000):\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        deg_files = sorted([f for f in os.listdir(deg_dir) if f.startswith(\"degraded_\")])\n",
    "        hr_set = set(os.listdir(hr_dir))\n",
    "\n",
    "        self.pairs = []\n",
    "        for f in deg_files:\n",
    "            clean = f.replace(\"degraded_\", \"\")\n",
    "            if clean in hr_set:\n",
    "                self.pairs.append((f, clean))\n",
    "\n",
    "        self.pairs = self.pairs[:max_items]\n",
    "        print(\"Aligned pairs:\", len(self.pairs))\n",
    "\n",
    "        self._build_cache(deg_dir, hr_dir)\n",
    "\n",
    "    def _build_cache(self, deg_dir, hr_dir):\n",
    "        print(\"Building cache (only once)...\")\n",
    "        for i, (d, h) in enumerate(tqdm(self.pairs)):\n",
    "            path = os.path.join(self.cache_dir, f\"{i:06d}.pt\")\n",
    "            if os.path.exists(path):\n",
    "                continue\n",
    "\n",
    "            deg = Image.open(os.path.join(deg_dir, d)).convert(\"RGB\")\n",
    "            hr  = Image.open(os.path.join(hr_dir, h)).convert(\"RGB\")\n",
    "\n",
    "            deg = transform_rgb(deg)\n",
    "            hr  = transform_rgb(hr)\n",
    "\n",
    "            L = rgb_to_luma(deg)\n",
    "            torch.save({\"L\": L, \"target\": hr}, path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.load(os.path.join(self.cache_dir, f\"{idx:06d}.pt\"), map_location=\"cpu\")\n",
    "\n",
    "        # L est obligatoire\n",
    "        L = data[\"L\"]\n",
    "\n",
    "        # target peut avoir plusieurs noms selon tes anciens scripts\n",
    "        if \"target\" in data:\n",
    "            target = data[\"target\"]\n",
    "        elif \"target_rgb\" in data:\n",
    "            target = data[\"target_rgb\"]\n",
    "        elif \"hr\" in data:\n",
    "            target = data[\"hr\"]\n",
    "        else:\n",
    "            raise KeyError(f\"Unknown keys in cache file: {data.keys()}\")\n",
    "\n",
    "        return L, target\n",
    "\n",
    "# ============================\n",
    "# 6) UNET (light)\n",
    "# ============================\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class UNetRGB(nn.Module):\n",
    "    def __init__(self, base=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.inc = DoubleConv(1, base)          # 128x128\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),                    # 64x64\n",
    "            DoubleConv(base, base*2)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),                    # 32x32\n",
    "            DoubleConv(base*2, base*4)\n",
    "        )\n",
    "\n",
    "        self.mid = DoubleConv(base*4, base*4)   # 32x32\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)  # 64x64\n",
    "        self.conv1 = DoubleConv(base*4 + base*2, base*2)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)  # 128x128\n",
    "        self.conv2 = DoubleConv(base*2 + base, base)\n",
    "\n",
    "        self.out = nn.Conv2d(base, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)     # 128\n",
    "        x2 = self.down1(x1)  # 64\n",
    "        x3 = self.down2(x2)  # 32\n",
    "\n",
    "        xm = self.mid(x3)\n",
    "\n",
    "        x = self.up1(xm)              # 64\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.up2(x)               # 128\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        return torch.sigmoid(self.out(x))  # [0,1]\n",
    "\n",
    "# ============================\n",
    "# 7) TRAIN CONFIG\n",
    "# ============================\n",
    "BATCH_SIZE = 8 if DEVICE.type == \"cuda\" else 1\n",
    "EPOCHS = 6\n",
    "LR = 2e-4\n",
    "MAX_ITEMS = 8000\n",
    "\n",
    "dataset = ColorDataset(DEG_DIR, HR_DIR, CACHE_DIR, max_items=MAX_ITEMS)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "model = UNetRGB(base=32).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# ============================\n",
    "# 8) TRAIN LOOP\n",
    "# ============================\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for L, target in loop:\n",
    "        L = L.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "\n",
    "        pred = model(L)\n",
    "        loss = criterion(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=float(loss.item()))\n",
    "\n",
    "    avg = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1} | Avg Loss: {avg:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{CHECKPOINT_DIR}/color_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        L, target = next(iter(loader))\n",
    "        pred = model(L.to(DEVICE)).cpu()\n",
    "\n",
    "        # grid: input(gray->rgb), pred, gt\n",
    "        # On convertit L en 3 canaux pour visualiser\n",
    "        L3 = L.repeat(1,3,1,1)\n",
    "\n",
    "        grid = torch.cat([L3[:4], pred[:4], target[:4]], dim=0)\n",
    "        utils.save_image(grid, f\"{GRID_DIR}/epoch_{epoch+1}.png\", nrow=4)\n",
    "\n",
    "print(\"✅ DONE. Check:\", GRID_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
