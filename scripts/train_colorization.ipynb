{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a1a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "Aligned pairs: 8000\n",
      "Building cache (only once)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:00<00:00, 18965.50it/s]\n",
      "Epoch 1/6: 100%|██████████| 8000/8000 [1:07:05<00:00,  1.99it/s, loss=0.0474]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Avg Loss: 0.0772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/6: 100%|██████████| 8000/8000 [34:46<00:00,  3.84it/s, loss=0.0742]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Avg Loss: 0.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/6: 100%|██████████| 8000/8000 [30:19<00:00,  4.40it/s, loss=0.0835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Avg Loss: 0.0704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/6: 100%|██████████| 8000/8000 [30:38<00:00,  4.35it/s, loss=0.171] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Avg Loss: 0.0699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/6: 100%|██████████| 8000/8000 [32:48<00:00,  4.07it/s, loss=0.0512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Avg Loss: 0.0697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/6: 100%|██████████| 8000/8000 [30:12<00:00,  4.41it/s, loss=0.0431]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Avg Loss: 0.0695\n",
      "✅ DONE. Check: samples_colorclean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# 1) DEVICE\n",
    "# ============================\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# ============================\n",
    "# 2) PATHS\n",
    "# ============================\n",
    "DEG_DIR = \"../data/train/degraded_images\"\n",
    "HR_DIR  = \"../data/train/images\"\n",
    "\n",
    "CACHE_DIR = \"cache_color\"\n",
    "CHECKPOINT_DIR = \"checkpoints_color\"\n",
    "GRID_DIR = \"samples_colorclean\"\n",
    "\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(GRID_DIR, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 3) TRANSFORMS\n",
    "# ============================\n",
    "transform_rgb = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),  # [0,1]\n",
    "])\n",
    "\n",
    "# ============================\n",
    "# 4) LUMA (pseudo grayscale)\n",
    "# ============================\n",
    "def rgb_to_luma(rgb01):\n",
    "    r, g, b = rgb01[0], rgb01[1], rgb01[2]\n",
    "    y = 0.299*r + 0.587*g + 0.114*b\n",
    "    return y.unsqueeze(0)  # [1,H,W]\n",
    "\n",
    "# ============================\n",
    "# 5) DATASET + CACHE\n",
    "# ============================\n",
    "class ColorDataset(Dataset):\n",
    "    \"\"\"\n",
    "    On fait simple :\n",
    "    Input = Luma(degraded)  [1,H,W]\n",
    "    Target = HR RGB         [3,H,W]\n",
    "\n",
    "    Cache = accélère énormément (sinon on relit + resize + calcule à chaque epoch)\n",
    "    \"\"\"\n",
    "    def __init__(self, deg_dir, hr_dir, cache_dir, max_items=8000):\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        deg_files = sorted([f for f in os.listdir(deg_dir) if f.startswith(\"degraded_\")])\n",
    "        hr_set = set(os.listdir(hr_dir))\n",
    "\n",
    "        self.pairs = []\n",
    "        for f in deg_files:\n",
    "            clean = f.replace(\"degraded_\", \"\")\n",
    "            if clean in hr_set:\n",
    "                self.pairs.append((f, clean))\n",
    "\n",
    "        self.pairs = self.pairs[:max_items]\n",
    "        print(\"Aligned pairs:\", len(self.pairs))\n",
    "\n",
    "        self._build_cache(deg_dir, hr_dir)\n",
    "\n",
    "    def _build_cache(self, deg_dir, hr_dir):\n",
    "        print(\"Building cache (only once)...\")\n",
    "        for i, (d, h) in enumerate(tqdm(self.pairs)):\n",
    "            path = os.path.join(self.cache_dir, f\"{i:06d}.pt\")\n",
    "            if os.path.exists(path):\n",
    "                continue\n",
    "\n",
    "            deg = Image.open(os.path.join(deg_dir, d)).convert(\"RGB\")\n",
    "            hr  = Image.open(os.path.join(hr_dir, h)).convert(\"RGB\")\n",
    "\n",
    "            deg = transform_rgb(deg)\n",
    "            hr  = transform_rgb(hr)\n",
    "\n",
    "            L = rgb_to_luma(deg)\n",
    "            torch.save({\"L\": L, \"target\": hr}, path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.load(os.path.join(self.cache_dir, f\"{idx:06d}.pt\"), map_location=\"cpu\")\n",
    "\n",
    "        # L est obligatoire\n",
    "        L = data[\"L\"]\n",
    "\n",
    "        # target peut avoir plusieurs noms selon tes anciens scripts\n",
    "        if \"target\" in data:\n",
    "            target = data[\"target\"]\n",
    "        elif \"target_rgb\" in data:\n",
    "            target = data[\"target_rgb\"]\n",
    "        elif \"hr\" in data:\n",
    "            target = data[\"hr\"]\n",
    "        else:\n",
    "            raise KeyError(f\"Unknown keys in cache file: {data.keys()}\")\n",
    "\n",
    "        return L, target\n",
    "\n",
    "# ============================\n",
    "# 6) UNET (light)\n",
    "# ============================\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class UNetRGB(nn.Module):\n",
    "    def __init__(self, base=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.inc = DoubleConv(1, base)          # 128x128\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),                    # 64x64\n",
    "            DoubleConv(base, base*2)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),                    # 32x32\n",
    "            DoubleConv(base*2, base*4)\n",
    "        )\n",
    "\n",
    "        self.mid = DoubleConv(base*4, base*4)   # 32x32\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)  # 64x64\n",
    "        self.conv1 = DoubleConv(base*4 + base*2, base*2)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)  # 128x128\n",
    "        self.conv2 = DoubleConv(base*2 + base, base)\n",
    "\n",
    "        self.out = nn.Conv2d(base, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)     # 128\n",
    "        x2 = self.down1(x1)  # 64\n",
    "        x3 = self.down2(x2)  # 32\n",
    "\n",
    "        xm = self.mid(x3)\n",
    "\n",
    "        x = self.up1(xm)              # 64\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.up2(x)               # 128\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        return torch.sigmoid(self.out(x))  # [0,1]\n",
    "\n",
    "# ============================\n",
    "# 7) TRAIN CONFIG\n",
    "# ============================\n",
    "BATCH_SIZE = 8 if DEVICE.type == \"cuda\" else 1\n",
    "EPOCHS = 6\n",
    "LR = 2e-4\n",
    "MAX_ITEMS = 8000\n",
    "\n",
    "dataset = ColorDataset(DEG_DIR, HR_DIR, CACHE_DIR, max_items=MAX_ITEMS)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "model = UNetRGB(base=32).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# ============================\n",
    "# 8) TRAIN LOOP\n",
    "# ============================\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for L, target in loop:\n",
    "        L = L.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "\n",
    "        pred = model(L)\n",
    "        loss = criterion(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=float(loss.item()))\n",
    "\n",
    "    avg = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1} | Avg Loss: {avg:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{CHECKPOINT_DIR}/color_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        L, target = next(iter(loader))\n",
    "        pred = model(L.to(DEVICE)).cpu()\n",
    "\n",
    "        # grid: input(gray->rgb), pred, gt\n",
    "        # On convertit L en 3 canaux pour visualiser\n",
    "        L3 = L.repeat(1,3,1,1)\n",
    "\n",
    "        grid = torch.cat([L3[:4], pred[:4], target[:4]], dim=0)\n",
    "        utils.save_image(grid, f\"{GRID_DIR}/epoch_{epoch+1}.png\", nrow=4)\n",
    "\n",
    "print(\"✅ DONE. Check:\", GRID_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61efdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints_color/color_restored_epoch_8.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 125\u001b[39m\n\u001b[32m    122\u001b[39m cnn1.eval()\n\u001b[32m    124\u001b[39m cnn2 = UNetRGB(base=\u001b[32m32\u001b[39m).to(DEVICE)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m cnn2.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCNN2_CKPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    126\u001b[39m cnn2.eval()\n\u001b[32m    128\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Models loaded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tassili\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tassili\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tassili\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'checkpoints_color/color_restored_epoch_8.pth'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "# ============================\n",
    "# DEVICE\n",
    "# ============================\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# ============================\n",
    "# PATHS\n",
    "# ============================\n",
    "DEG_DIR = \"../data/test/degraded_images\"   # prends TEST pour voir un vrai rendu\n",
    "HR_DIR  = \"../data/test/images\"\n",
    "\n",
    "CNN1_CKPT = \"checkpoints/epoch_8.pth\"\n",
    "CNN2_CKPT = \"checkpoints_color/color_epoch_8.pth\"  # ou ton dernier\n",
    "\n",
    "OUT_GRID = \"grid_compare.png\"\n",
    "\n",
    "# ============================\n",
    "# TRANSFORM\n",
    "# ============================\n",
    "transform_rgb = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ============================\n",
    "# CNN1 ARCHI\n",
    "# ============================\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch, ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return torch.relu(x + self.block(x))\n",
    "\n",
    "class ElegantCNN(nn.Module):\n",
    "    def __init__(self, in_ch=3, base_ch=64, n_blocks=6):\n",
    "        super().__init__()\n",
    "        self.inp = nn.Conv2d(in_ch, base_ch, 3, padding=1)\n",
    "        self.body = nn.Sequential(*[ResidualBlock(base_ch) for _ in range(n_blocks)])\n",
    "        self.out = nn.Conv2d(base_ch, in_ch, 3, padding=1)\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = torch.relu(self.inp(x))\n",
    "        x = self.body(x)\n",
    "        x = self.out(x)\n",
    "        return torch.tanh(x + identity)\n",
    "\n",
    "# ============================\n",
    "# CNN2 ARCHI\n",
    "# ============================\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class UNetRGB(nn.Module):\n",
    "    def __init__(self, base=32):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(1, base)\n",
    "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(base, base*2))\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(base*2, base*4))\n",
    "        self.mid = DoubleConv(base*4, base*4)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        self.conv1 = DoubleConv(base*4 + base*2, base*2)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        self.conv2 = DoubleConv(base*2 + base, base)\n",
    "\n",
    "        self.out = nn.Conv2d(base, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        xm = self.mid(x3)\n",
    "\n",
    "        x = self.up1(xm)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        return torch.sigmoid(self.out(x))\n",
    "\n",
    "# ============================\n",
    "# UTILS\n",
    "# ============================\n",
    "def rgb_to_luma(rgb01):\n",
    "    r, g, b = rgb01[:,0], rgb01[:,1], rgb01[:,2]  # batch\n",
    "    y = 0.299*r + 0.587*g + 0.114*b\n",
    "    return y.unsqueeze(1)  # [B,1,H,W]\n",
    "\n",
    "# ============================\n",
    "# LOAD MODELS\n",
    "# ============================\n",
    "cnn1 = ElegantCNN().to(DEVICE)\n",
    "cnn1.load_state_dict(torch.load(CNN1_CKPT, map_location=DEVICE))\n",
    "cnn1.eval()\n",
    "\n",
    "cnn2 = UNetRGB(base=32).to(DEVICE)\n",
    "cnn2.load_state_dict(torch.load(CNN2_CKPT, map_location=DEVICE))\n",
    "cnn2.eval()\n",
    "\n",
    "print(\"✅ Models loaded\")\n",
    "\n",
    "# ============================\n",
    "# BUILD MINI DATASET (just for grid)\n",
    "# ============================\n",
    "deg_files = sorted([f for f in os.listdir(DEG_DIR) if f.startswith(\"degraded_\")])[:8]\n",
    "\n",
    "degs, hrs = [], []\n",
    "for f in deg_files:\n",
    "    clean_name = f.replace(\"degraded_\", \"\")\n",
    "    deg = Image.open(os.path.join(DEG_DIR, f)).convert(\"RGB\")\n",
    "    hr  = Image.open(os.path.join(HR_DIR, clean_name)).convert(\"RGB\")\n",
    "    degs.append(transform_rgb(deg))\n",
    "    hrs.append(transform_rgb(hr))\n",
    "\n",
    "deg_batch = torch.stack(degs).to(DEVICE)   # [B,3,128,128] in [0,1]\n",
    "hr_batch  = torch.stack(hrs).to(DEVICE)\n",
    "\n",
    "# ============================\n",
    "# FORWARD\n",
    "# ============================\n",
    "with torch.no_grad():\n",
    "    # CNN1 wants [-1,1]\n",
    "    deg_in = deg_batch * 2 - 1\n",
    "    restored = cnn1(deg_in)                # [-1,1]\n",
    "    restored01 = (restored + 1) / 2        # [0,1]\n",
    "\n",
    "    # CNN2 input = L(restored)\n",
    "    L = rgb_to_luma(restored01)\n",
    "    pred_rgb = cnn2(L)                     # [0,1]\n",
    "\n",
    "# ============================\n",
    "# SAVE GRID\n",
    "# ============================\n",
    "# 4 rows: degraded / restored / colorized / gt\n",
    "grid = torch.cat([\n",
    "    deg_batch.cpu(),\n",
    "    restored01.cpu(),\n",
    "    pred_rgb.cpu(),\n",
    "    hr_batch.cpu()\n",
    "], dim=0)\n",
    "\n",
    "utils.save_image(grid, OUT_GRID, nrow=len(deg_files))\n",
    "print(\"✅ Grid saved:\", OUT_GRID)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
