{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VAE-UNET HYBRIDE ---\n",
    "class VAE_UNet(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(VAE_UNet, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # ENCODEUR avec skip connections\n",
    "        self.enc1 = self.conv_block(3, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # BOTTLENECK - Espace latent VAE\n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Couches VAE (mu et logvar)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_mu = nn.Linear(1024 * 8 * 8, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(1024 * 8 * 8, latent_dim)\n",
    "        \n",
    "        # Reconstruction depuis l'espace latent\n",
    "        self.fc_decode = nn.Linear(latent_dim, 1024 * 8 * 8)\n",
    "        self.unflatten = nn.Unflatten(1, (1024, 8, 8))\n",
    "        \n",
    "        # DÉCODEUR avec skip connections (style U-Net)\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)  # 1024 = 512 (up) + 512 (skip)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)  # 512 = 256 (up) + 256 (skip)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)  # 256 = 128 (up) + 128 (skip)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)  # 128 = 64 (up) + 64 (skip)\n",
    "        \n",
    "        # Sortie finale\n",
    "        self.out = nn.Conv2d(64, 3, 1)\n",
    "    \n",
    "    def conv_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # Encodeur avec sauvegarde des skip connections\n",
    "        e1 = self.enc1(x)          # 128x128x64\n",
    "        p1 = self.pool1(e1)\n",
    "        \n",
    "        e2 = self.enc2(p1)         # 64x64x128\n",
    "        p2 = self.pool2(e2)\n",
    "        \n",
    "        e3 = self.enc3(p2)         # 32x32x256\n",
    "        p3 = self.pool3(e3)\n",
    "        \n",
    "        e4 = self.enc4(p3)         # 16x16x512\n",
    "        p4 = self.pool4(e4)\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p4)    # 8x8x1024\n",
    "        \n",
    "        # VAE latent space\n",
    "        flat = self.flatten(b)\n",
    "        mu = self.fc_mu(flat)\n",
    "        logvar = self.fc_logvar(flat)\n",
    "        \n",
    "        return mu, logvar, e1, e2, e3, e4\n",
    "    \n",
    "    def decode(self, z, e1, e2, e3, e4):\n",
    "        # Reconstruction depuis l'espace latent\n",
    "        x = self.fc_decode(z)\n",
    "        x = self.unflatten(x)      # 8x8x1024\n",
    "        \n",
    "        # Décodeur avec skip connections\n",
    "        d4 = self.up4(x)           # 16x16x512\n",
    "        d4 = torch.cat([d4, e4], dim=1)  # Concat avec skip\n",
    "        d4 = self.dec4(d4)\n",
    "        \n",
    "        d3 = self.up3(d4)          # 32x32x256\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = self.up2(d3)          # 64x64x128\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        d1 = self.up1(d2)          # 128x128x64\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        out = self.out(d1)         # 128x128x3\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar, e1, e2, e3, e4 = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z, e1, e2, e3, e4)\n",
    "        return recon, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RestorationDataset(Dataset):\n",
    "    def __init__(self, degraded_dir, clean_dir, transform=None):\n",
    "        self.degraded_dir = degraded_dir\n",
    "        self.clean_dir = clean_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        degraded_files = set(os.listdir(degraded_dir))\n",
    "        clean_files = set(os.listdir(clean_dir))\n",
    "        \n",
    "        self.filenames = []\n",
    "        for deg_file in degraded_files:\n",
    "            clean_file = deg_file.replace(\"degraded_\", \"\")\n",
    "            if clean_file in clean_files:\n",
    "                self.filenames.append(deg_file)\n",
    "        \n",
    "        print(f\"{len(self.filenames)} paires d'images trouvées\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        degraded_filename = self.filenames[idx]\n",
    "        clean_filename = degraded_filename.replace(\"degraded_\", \"\")\n",
    "        \n",
    "        degraded_path = os.path.join(self.degraded_dir, degraded_filename)\n",
    "        clean_path = os.path.join(self.clean_dir, clean_filename)\n",
    "        \n",
    "        degraded_img = Image.open(degraded_path).convert('RGB')\n",
    "        clean_img = Image.open(clean_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            degraded_img = self.transform(degraded_img)\n",
    "            clean_img = self.transform(clean_img)\n",
    "        \n",
    "        return degraded_img, clean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(recon, target, mu, logvar, beta=0.0001):\n",
    "    \"\"\"\n",
    "    Loss VAE optimisée :\n",
    "    - L1 : netteté\n",
    "    - MSE : structure\n",
    "    - KL divergence : régularisation\n",
    "    \"\"\"\n",
    "    l1_loss = nn.functional.l1_loss(recon, target, reduction='sum')\n",
    "    mse_loss = nn.functional.mse_loss(recon, target, reduction='sum')\n",
    "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    total_loss = l1_loss + 0.5 * mse_loss + beta * kld_loss\n",
    "    \n",
    "    return total_loss, l1_loss.item(), mse_loss.item(), kld_loss.item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(model, dataloader, epoch, device, output_dir=\"samples\", num_samples=8):\n",
    "    \"\"\"Génère et sauvegarde des échantillons de restauration\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        degraded, clean = next(iter(dataloader))\n",
    "        degraded, clean = degraded[:num_samples].to(device), clean[:num_samples].to(device)\n",
    "        \n",
    "        restored, _, _ = model(degraded)\n",
    "        \n",
    "        # Grille : [dégradée | restaurée | propre]\n",
    "        comparison = torch.cat([degraded, restored, clean], dim=0)\n",
    "        save_image(comparison, \n",
    "                   os.path.join(output_dir, f\"epoch_{epoch:03d}.png\"),\n",
    "                   nrow=num_samples, \n",
    "                   normalize=False)\n",
    "    \n",
    "    model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Utilisation de : {device}\")\n",
    "    \n",
    "    # Modèle VAE-UNet\n",
    "    model = VAE_UNet(latent_dim=256).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3\n",
    "    )\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    path_degraded = \"../data/train/degraded_images/\"\n",
    "    path_clean = \"../data/train/images/\"\n",
    "    \n",
    "    dataset = RestorationDataset(path_degraded, path_clean, transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=32,\n",
    "        shuffle=True, \n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    os.makedirs(\"samples\", exist_ok=True)\n",
    "    \n",
    "    num_epochs = 50\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    print(\"Génération des échantillons initiaux...\")\n",
    "    save_samples(model, dataloader, 0, device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_l1 = 0\n",
    "        epoch_mse = 0\n",
    "        epoch_kld = 0\n",
    "        \n",
    "        progress_bar = tqdm(dataloader, desc=f\"Époque {epoch+1}/{num_epochs}\", file=sys.stdout)\n",
    "        \n",
    "        for batch_idx, (degraded, clean) in enumerate(progress_bar):\n",
    "            degraded, clean = degraded.to(device), clean.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            restored, mu, logvar = model(degraded)\n",
    "            loss, l1, mse, kld = vae_loss_function(restored, clean, mu, logvar)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_l1 += l1\n",
    "            epoch_mse += mse\n",
    "            epoch_kld += kld\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f'{loss.item()/len(degraded):.4f}',\n",
    "                    'l1': f'{l1/len(degraded):.2f}',\n",
    "                    'kld': f'{kld/len(degraded):.2f}'\n",
    "                })\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataset)\n",
    "        scheduler.step(avg_loss)\n",
    "        \n",
    "        print(f\"\\nÉpoque {epoch+1} | Loss: {avg_loss:.4f} | \"\n",
    "              f\"L1: {epoch_l1/len(dataset):.4f} | \"\n",
    "              f\"MSE: {epoch_mse/len(dataset):.4f} | \"\n",
    "              f\"KLD: {epoch_kld/len(dataset):.4f}\")\n",
    "        \n",
    "        # Génération d'échantillons tous les 2 epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f\"Génération d'échantillons...\")\n",
    "            save_samples(model, dataloader, epoch + 1, device)\n",
    "        \n",
    "        # Sauvegarde du meilleur modèle\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }, \"vae_unet_best.pth\")\n",
    "            print(f\"Meilleur modèle sauvegardé (loss: {best_loss:.4f})\")\n",
    "        \n",
    "        # Checkpoints réguliers\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), f\"vae_unet_epoch_{epoch+1}.pth\")\n",
    "    \n",
    "    print(\"\\nEntraînement terminé !\")\n",
    "    print(f\"Les échantillons sont dans le dossier 'samples/'\")\n",
    "    print(f\"Meilleur modèle : vae_unet_best.pth (loss: {best_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "test_degraded_dir = \"../data/test/degraded_images/\"\n",
    "test_clean_dir = \"../data/test/images/\"\n",
    "output_dir = \"test_results_metrics\"\n",
    "checkpoint_path = \"vae_unet_best.pth\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- CHARGEMENT DU MODÈLE ---\n",
    "model = VAE_UNet(latent_dim=256).to(device)\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# --- BOUCLE DE TEST ---\n",
    "filenames = [f for f in os.listdir(test_degraded_dir) if f.endswith(('.jpg', '.png'))]\n",
    "all_psnr = []\n",
    "all_ssim = []\n",
    "\n",
    "print(f\"Évaluation de {len(filenames)} images de test...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for filename in tqdm(filenames):\n",
    "        # 1. Chargement des images\n",
    "        deg_path = os.path.join(test_degraded_dir, filename)\n",
    "        clean_filename = filename.replace(\"degraded_\", \"\")\n",
    "        clean_path = os.path.join(test_clean_dir, clean_filename)\n",
    "\n",
    "        if not os.path.exists(clean_path): continue\n",
    "\n",
    "        img_deg = transform(Image.open(deg_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "        img_clean = transform(Image.open(clean_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "        # 2. Inférence\n",
    "        img_restored, _, _ = model(img_deg)\n",
    "\n",
    "        # 3. Conversion pour calcul des métriques (Tenseur -> Numpy HWC [0,1])\n",
    "        # On détache et on déplace sur CPU\n",
    "        clean_np = img_clean.squeeze().cpu().permute(1, 2, 0).numpy()\n",
    "        restored_np = img_restored.squeeze().cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "        # 4. Calcul des scores\n",
    "        # data_range=1.0 car nos pixels sont entre 0 et 1\n",
    "        current_psnr = psnr(clean_np, restored_np, data_range=1.0)\n",
    "        current_ssim = ssim(clean_np, restored_np, data_range=1.0, channel_axis=2)\n",
    "\n",
    "        all_psnr.append(current_psnr)\n",
    "        all_ssim.append(current_ssim)\n",
    "\n",
    "        # 5. Sauvegarde visuelle (Optionnel)\n",
    "        comparison = torch.cat([img_deg, img_restored, img_clean], dim=0)\n",
    "        save_image(comparison, os.path.join(output_dir, f\"score_{current_psnr:.2f}_{filename}\"), nrow=3)\n",
    "\n",
    "# --- RÉSULTATS FINAUX ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"RÉSULTATS DU MODÈLE SUR LE TEST SET\")\n",
    "print(f\"PSNR Moyen : {np.mean(all_psnr):.2f} dB\")\n",
    "print(f\"SSIM Moyen : {np.mean(all_ssim):.4f}\")\n",
    "print(\"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
