{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch_directml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.d2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(128, affine=True),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.d3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(256, affine=True),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.u1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(256, 128, 3, 1, 1),\n",
    "            nn.InstanceNorm2d(128, affine=True),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.u2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(256, 64, 3, 1, 1),\n",
    "            nn.InstanceNorm2d(64, affine=True),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.u3 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(128, 3, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.d1(x)\n",
    "        d2 = self.d2(d1)\n",
    "        d3 = self.d3(d2)\n",
    "\n",
    "        # Decoder avec des skip connections\n",
    "        u1 = self.u1(d3)\n",
    "        u1 = torch.cat([u1, d2], dim=1)\n",
    "\n",
    "        u2 = self.u2(u1)\n",
    "        u2 = torch.cat([u2, d1], dim=1)\n",
    "\n",
    "        return self.u3(u2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, 4, 2, 1),   # image_détériorée + image\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(128, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(256, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 1, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_cond, img):\n",
    "        x = torch.cat([img_cond, img], dim=1)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# CHARGEMENT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paired_dataset import PairedImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = PairedImageDataset(\"..\\\\..\\\\data\\\\train\")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=6, #--> à adapter selon le nombre de coeurs dispo\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "degraded, target = next(iter(dataloader))\n",
    "print(degraded.shape, target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch_directml.device()\n",
    "\n",
    "output_dir = \"output_gan\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "gen = Generator().to(device)\n",
    "disc = Discriminator().to(device)\n",
    "\n",
    "opt_g = optim.Adam(gen.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "opt_d = optim.Adam(disc.parameters(), lr=5e-5, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_loss(x):\n",
    "    return torch.mean(torch.abs(x[:, :, :-1] - x[:, :, 1:])) + \\\n",
    "           torch.mean(torch.abs(x[:, :, :, :-1] - x[:, :, :, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICI ce training est adapté pour du GPU AMD \n",
    "# Le modèle final n'est pas entrainé via AMD mais via le fichier ganGpu_model.ipynb\n",
    "#(Quelques modifications mineures sont visibles entre les deux fichiers (ex : dans le fichier GPU on peut executer des entrainements en partant d'un .pth))\n",
    "\n",
    "epochs = 100\n",
    "save_every = 2\n",
    "\n",
    "fixed_cond = next(iter(dataloader))[0][:25].to(device)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "\n",
    "    # barre de progression sur les batches\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch [{epoch}/{epochs}]\", leave=False)\n",
    "\n",
    "    for degraded, target in pbar:\n",
    "        degraded = degraded.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # ---- Discriminator ----\n",
    "        opt_d.zero_grad()\n",
    "        out_real = disc(degraded, target)\n",
    "        real_labels = torch.full_like(out_real, 0.9, device=device)\n",
    "        d_loss_real = criterion(out_real, real_labels)\n",
    "\n",
    "        fake = gen(degraded)\n",
    "        out_fake = disc(degraded, fake.detach())\n",
    "        fake_labels = torch.zeros_like(out_fake, device=device)\n",
    "        d_loss_fake = criterion(out_fake, fake_labels)\n",
    "\n",
    "        d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "        d_loss.backward()\n",
    "        opt_d.step()\n",
    "\n",
    "\n",
    "        # ---- Generator ----\n",
    "        #On fait deux entraînements du générateur par itération --> cela aide à stabiliser l'entrainement\n",
    "        for _ in range(2):\n",
    "            opt_g.zero_grad()\n",
    "            out_fake_for_g = disc(degraded, fake)\n",
    "            real_labels_g = torch.ones_like(out_fake_for_g)\n",
    "\n",
    "            #On adapte le poids du L1 en fonction de l'epoque (on le décroit au fur et à mesure)\n",
    "            if epoch < 7:\n",
    "                lambda_l1 = 40\n",
    "            elif epoch < 25:\n",
    "                lambda_l1 = 15\n",
    "            else:\n",
    "                lambda_l1 = 7\n",
    "\n",
    "                \n",
    "            adv_loss = criterion(out_fake_for_g, real_labels_g)\n",
    "            l1_loss = torch.nn.functional.l1_loss(fake, target)\n",
    "\n",
    "            if epoch <= 7 : #On warmup le generateur donc pas de adv_loss\n",
    "                g_loss = lambda_l1 * l1_loss\n",
    "            else :\n",
    "                tv = tv_loss(fake) #On ajoute une régularisation de variation totale\n",
    "                g_loss = adv_loss + lambda_l1 * l1_loss + 0.005 * tv\n",
    "\n",
    "            g_loss.backward()\n",
    "            opt_g.step()\n",
    "\n",
    "        #Stockage des pertes pour affichage\n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "\n",
    "        # mise à jour de la barre\n",
    "        pbar.set_postfix({\n",
    "            \"G_loss\": f\"{g_loss.item():.3f}\",\n",
    "            \"D_loss\": f\"{d_loss.item():.3f}\"\n",
    "        })\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}: \"\n",
    "        f\"gen_loss={np.mean(g_losses):.4f}, \"\n",
    "        f\"disc_loss={np.mean(d_losses):.4f}\"\n",
    "    )\n",
    "\n",
    "    #Sauvegarde des échantillons générés\n",
    "    if epoch % save_every == 0 or epoch in (1, epochs):\n",
    "        with torch.no_grad():\n",
    "            gen.eval()\n",
    "            samples = gen(fixed_cond)\n",
    "            samples = (samples + 1) / 2.0\n",
    "            samples = samples.cpu() \n",
    "            grid = make_grid(samples, nrow=5)\n",
    "            save_image(\n",
    "                grid,\n",
    "                os.path.join(output_dir, f\"generated_epoch_{epoch}.png\")\n",
    "            )\n",
    "            gen.train()\n",
    "    \n",
    "    #Sauvegarde du modèle toutes les 10 époques\n",
    "    if epoch % 10 == 0 or epoch == epochs:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"gen_state_dict\": gen.state_dict(),\n",
    "                \"disc_state_dict\": disc.state_dict(),\n",
    "                \"opt_g_state_dict\": opt_g.state_dict(),\n",
    "                \"opt_d_state_dict\": opt_d.state_dict(),\n",
    "            },\n",
    "            os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "        )\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
